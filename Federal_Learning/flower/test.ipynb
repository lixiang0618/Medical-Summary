{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeba9316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "     ---------------------------------------- 4.0/4.0 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in e:\\python\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.9.1 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torchvision) (2.9.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torch==2.9.1->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torch==2.9.1->torchvision) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torch==2.9.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torch==2.9.1->torchvision) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in e:\\python\\lib\\site-packages (from torch==2.9.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from torch==2.9.1->torchvision) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python\\pycharm community edition 2023.2.1\\medical_dialogue_summary\\venv\\lib\\site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python\\lib\\site-packages (from jinja2->torch==2.9.1->torchvision) (2.1.5)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5187ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1757cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(client_id):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    trainset = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # 简单切分数据（模拟非 IID）\n",
    "    indices = list(range(len(trainset)))\n",
    "    split = len(indices) // 2\n",
    "    if client_id == 0:\n",
    "        trainset.data = trainset.data[:split]\n",
    "        trainset.targets = trainset.targets[:split]\n",
    "    else:\n",
    "        trainset.data = trainset.data[split:]\n",
    "        trainset.targets = trainset.targets[split:]\n",
    "\n",
    "    return (\n",
    "        DataLoader(trainset, batch_size=32, shuffle=True),\n",
    "        DataLoader(testset, batch_size=32),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b86315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, client_id):\n",
    "        self.model = Net()\n",
    "        self.trainloader, self.testloader = load_data(client_id)\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [v.cpu().numpy() for v in self.model.state_dict().values()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params = zip(self.model.state_dict().keys(), parameters)\n",
    "        self.model.load_state_dict(\n",
    "            {k: torch.tensor(v) for k, v in params}, strict=True\n",
    "        )\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "\n",
    "        for _ in range(1):\n",
    "            for x, y in self.trainloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.criterion(self.model(x), y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        print(f\"[Client {id(self)}] Local training done\")\n",
    "\n",
    "        return self.get_parameters(config), len(self.trainloader.dataset), {}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        loss, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.testloader:\n",
    "                out = self.model(x)\n",
    "                loss += self.criterion(out, y).item()\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "        return loss, len(self.testloader.dataset), {\n",
    "            \"accuracy\": correct / len(self.testloader.dataset)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb24a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
      "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
      "\n",
      "\t\t$ flower-superlink --insecure\n",
      "\n",
      "\tTo view usage and all available options, run:\n",
      "\n",
      "\t\t$ flower-superlink --help\n",
      "\n",
      "\tUsing `start_server()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=3, no round_timeout\n"
     ]
    }
   ],
   "source": [
    "def start_server():\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        min_fit_clients=2,\n",
    "        min_available_clients=2,\n",
    "    )\n",
    "    fl.server.start_server(\n",
    "        server_address=\"129.0.0.1:8080\",\n",
    "        config=fl.server.ServerConfig(num_rounds=3),\n",
    "        strategy=strategy,\n",
    "    )\n",
    "\n",
    "server_thread = threading.Thread(target=start_server)\n",
    "server_thread.start()\n",
    "\n",
    "time.sleep(2)  # 等 server 起来\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f07101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "Exception in thread Thread-56 (start_client):\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\python\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"E:\\python\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"E:\\python\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\pigeon\\AppData\\Local\\Temp\\ipykernel_18216\\111612193.py\", line 2, in start_client\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\app.py\", line 625, in start_numpy_client\n",
      "Exception in thread Thread-55 (start_client):\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\python\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"E:\\python\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"E:\\python\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\pigeon\\AppData\\Local\\Temp\\ipykernel_18216\\111612193.py\", line 2, in start_client\n",
      "    start_client(\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\app.py\", line 184, in start_client\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\app.py\", line 625, in start_numpy_client\n",
      "    start_client_internal(\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\app.py\", line 395, in start_client_internal\n",
      "    start_client(\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\app.py\", line 184, in start_client\n",
      "    start_client_internal(\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\app.py\", line 395, in start_client_internal\n",
      "    message = receive()\n",
      "              ^^^^^^^^^\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\grpc_client\\connection.py\", line 142, in receive\n",
      "    message = receive()\n",
      "              ^^^^^^^^^\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\flwr\\compat\\client\\grpc_client\\connection.py\", line 142, in receive\n",
      "    proto = next(server_message_iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\grpc\\_channel.py\", line 538, in __next__\n",
      "    proto = next(server_message_iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\grpc\\_channel.py\", line 538, in __next__\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\grpc\\_channel.py\", line 962, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNAVAILABLE\n",
      "\tdetails = \"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:129.0.0.1:8080: IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\n",
      " -- 10054)\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:129.0.0.1:8080: IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\\r\\n -- 10054)\"}\"\n",
      ">\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"e:\\python\\PyCharm Community Edition 2023.2.1\\Medical_Dialogue_Summary\\venv\\Lib\\site-packages\\grpc\\_channel.py\", line 962, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNAVAILABLE\n",
      "\tdetails = \"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:129.0.0.1:8080: IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\n",
      " -- 10054)\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNAVAILABLE: ipv4:129.0.0.1:8080: IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\\r\\n -- 10054)\", grpc_status:14}\"\n",
      ">\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "def start_client(client_id):\n",
    "    fl.client.start_numpy_client(\n",
    "        server_address=\"129.0.0.1:8080\",\n",
    "        client=FlowerClient(client_id),\n",
    "    )\n",
    "\n",
    "client_threads = []\n",
    "for cid in [0, 1]:\n",
    "    t = threading.Thread(target=start_client, args=(cid,))\n",
    "    t.start()\n",
    "    client_threads.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1ab30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
